# sudabib


[![Build status](https://img.shields.io/github/actions/workflow/status/strayMat/sudabib/main.yml?branch=main)](https://github.com/strayMat/sudabib/actions/workflows/main.yml?query=branch%3Amain)
[![codecov](https://codecov.io/gh/strayMat/sudabib/branch/main/graph/badge.svg)](https://codecov.io/gh/strayMat/sudabib)
[![Documentation](https://img.shields.io/badge/docs-latest-blue.svg)](https://strayMat.github.com/sudabib/)
[![License](https://img.shields.io/github/license/strayMat/sudabib)](https://img.shields.io/github/license/strayMat/sudabib)


> üìù **Note**
> Utilisez le fran√ßais pour tout le contenu de ce projet

---

## Description

> - Projet d'exploration des outils llm pour la revue de litt√©rature en interfa√ßant des llm avec la librarie openalex en utilisant comme pont entre les deux la [librairie llm de Simon Willison](https://github.com/simonw/llm)
> - Livrables : Outil python entrant une requ√™te en langage naturel concernant une question scientifique et renvoyant une r√©ponse sourc√©e gr√¢ce √† des abstracts d'articles scientifiques.
> - Destinataires: Chercheurs et rapporteurs pour d√©broussailler la revue initial de litt√©rature. 
> - Motivation: Envie de comprendre comment marche [llm]() et envie de mieux comprendre openalex.
>
> - Acteurs impliqu√©s : NA.
> - Temporalit√© du projet : 2025-05-29 lazy mode 
>
> Optionnel : une image qui permet de visualiser le r√©sultat du projet
> Ex :
>
> - capture d'√©cran d'un tableau de bord ou d'une application
> - figure marquante d'un rapport, etc.

## Liens utiles

- Documentation :
- Code source : 

> üìù **Explication du contenu √† r√©diger**
>
> Vous pouvez aussi rajouter d'autres liens utiles : protocole, rapport d'√©tude, lien site internet, tutoriels, guide utilisateur

## Contexte technique

### Donn√©es utilis√©es

> üìù **Explication du contenu √† r√©diger**
>
> D√©crire les donn√©es utilis√©es et leur √©ventuelles restrictions d'acc√®s.

### Sch√©ma flux de donn√©es (optionnel)

### Technologies

> üìù **Explication du contenu √† r√©diger**
>
> Donner quelques rep√®res sur les technologies utilis√©es : langage, logiciels, √©ventuellement dossiers o√π trouver le code, etc.

### Maintenance

> üìù **Explication du contenu √† r√©diger**
>
> Expliquer si le projet est maintenu et comment, par exemple parmi les alternatives suivantes :
>
> - Projet en d√©veloppement actif
> - Projet finalis√© ‚úÖ, sans maintenance ni modification
> - Maintenance minimale üìû, pour mettre √† jour les d√©pendances ou en cas de probl√®me
> - Maintenance planifi√©e ‚è∞, avec des t√¢ches r√©currentes √† r√©aliser (auquel cas d√©crire les t√¢ches et leur fr√©quence)

## Contacts

> üìù **Explication du contenu √† r√©diger**
>
> Description des contacts importants du projet, en pr√©cisant pour chacun :
>
> - l'organisation (service, p√¥le, etc),
> - le r√¥le sur le projet,
> - le contact mail (g√©n√©rique et non personnel).

## D√©tails techniques

### Installation and simple usage of LLM

- Installation: 

```
uv add llm
uv run llm install llm-mistral # install mistral plugin
uv run llm keys set mistral # go there for creating an API key for mistral
```

- Usage:

```
ul -m mistral-small "tell me a joke about pelican"
``` 

- Param√®tre un mod√®le par d√©faut, par exemple, un llama local (n√©cessite le t√©l√©chargement du plugin [llm-gpt4all](https://github.com/simonw/llm-gpt4all)):

```
uv run llm 

### En utilisant un serveur Ollama (permet d'avoir un mod√®le local instanci√© ie. charg√© en m√©moire) 

- Installer Ollama : `curl -fsSL https://ollama.com/install.sh | sh`

- T√©l√©charger un mod√®le en local, par exemple, Llama 3.1 1B : `ollama pull llama3.2:1b`

- 